# Questions

## Linear Regression for classification:

On 4.2 it says:

> For a binary response with a 0/1 coding as above, regression by least squares does make sense; it can be shown that the X^B obtained using linear regression is in fact an estimate of `P(drug overdose|X)`. Why?


## Average fitted value for linear and logistic regression:

On 4.3.1 it says:

> The average fitted probability in both cases is 0.0333, which is the same as the overall proportion of defaulters in the data set.

Prove this with code or analytically. 


## Logistic Regression coefficients go off to infinity:

On lecture [4.5 videos](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/courseware/41ce0170b29f43ab9d490b5f37d16fdf/6a799584d6824c3ba1c1db1ea35de419/) it says:

> If you've got a feature that separates the classes perfectly, the coefficients go off to infinity.

Prove this, understand why.
